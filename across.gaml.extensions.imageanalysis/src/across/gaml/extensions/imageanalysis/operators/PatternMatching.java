package across.gaml.extensions.imageanalysis.operators;

 
import java.awt.BasicStroke;
import java.awt.Dimension;
import java.awt.Graphics2D;
import java.awt.image.BufferedImage;
import java.awt.image.RescaleOp;
import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import javax.imageio.ImageIO;

import com.github.sarxos.webcam.Webcam;
import com.google.common.io.Files;

import across.gaml.extensions.imageanalysis.boofcv.RemovePerspectiveDistortion;
import across.gaml.extensions.imageanalysis.types.GamaWebcam;
import across.gaml.extensions.imageanalysis.types.PatternBlock;
import across.gaml.extensions.imageanalysis.types.PhysicalBlock;
import boofcv.alg.color.ColorRgb;
import boofcv.alg.enhance.EnhanceImageOps;
import boofcv.alg.enhance.GEnhanceImageOps;
import boofcv.alg.feature.detect.edge.CannyEdge;
import boofcv.alg.feature.detect.edge.EdgeContour;
import boofcv.alg.feature.detect.edge.EdgeSegment;
import boofcv.alg.filter.binary.BinaryImageOps;
import boofcv.alg.filter.binary.Contour;
import boofcv.alg.misc.ImageStatistics;
import boofcv.alg.shapes.ShapeFittingOps;
import boofcv.factory.feature.detect.edge.FactoryEdgeDetectors;
import boofcv.io.image.ConvertBufferedImage;
import boofcv.struct.ConnectRule;
import boofcv.struct.PointIndex_I32;
import boofcv.struct.image.GrayF32;
import boofcv.struct.image.GrayU8;
import boofcv.struct.image.ImageType;
import boofcv.struct.image.Planar;
import georegression.struct.point.Point2D_F64;
import georegression.struct.point.Point2D_I32;
import msi.gama.common.geometry.Envelope3D;
import msi.gama.common.util.FileUtils;
import msi.gama.metamodel.shape.GamaPoint;
import msi.gama.metamodel.shape.IShape;
import msi.gama.precompiler.GamlAnnotations.doc;
import msi.gama.precompiler.GamlAnnotations.operator;
import msi.gama.precompiler.IOperatorCategory;
import msi.gama.runtime.GAMA;
import msi.gama.runtime.IScope;
import msi.gama.runtime.exceptions.GamaRuntimeException;
import msi.gama.util.GamaListFactory;
import msi.gama.util.IList;
import msi.gama.util.matrix.GamaIntMatrix;
import msi.gama.util.matrix.IMatrix;

public class PatternMatching {
	// hdtrung - save 4 selected points of map: top-left, top-right, bottom-right, bottom-left
	//private static List<List<GamaIntMatrix>> current_matrix_map;
	//private static List<List<Integer>> current_int_map;
	


	private static List<BufferedImage> cropGrid(final BufferedImage bf, final int cols, final int rows, int expectedW, int expectedH,float threshLow, float threshHigh ) throws IOException {
		List<BufferedImage> result = new ArrayList<>();
		int width = bf.getWidth()/cols;
        int height = bf.getHeight()/rows;
        for (int i = 0; i < cols ; i++ ){
            for (int j = 0; j < rows ; j ++ ){
            	BufferedImage imC = bf.getSubimage(i*width, j*height, width, height);
            	imC = fitCannyBinary(imC,expectedW, expectedH, threshLow,  threshHigh );
            	
        		result.add(imC);
            }
        }
        return result;
    }
	
	
	static double cornerPenalty = 0.25;
	// The fewest number of pixels a side can have
	static int minSide = 10;

	

	
	/**
	 * Detects contours inside the binary image generated by canny. Only the external contour is relevant. Often
	 * easier to deal with than working with Canny edges directly.
	 */
	private static BufferedImage fitCannyBinary( BufferedImage image,int expectedW, int expectedH, float threshLow, float threshHigh  ) {
		GrayF32 input = ConvertBufferedImage.convertFromSingle(image, null, GrayF32.class);

		BufferedImage displayImage = new BufferedImage(input.width, input.height, BufferedImage.TYPE_INT_RGB);
		GrayU8 binary = new GrayU8(input.width, input.height);

		// Finds edges inside the image
		CannyEdge<GrayF32, GrayF32> canny =
				FactoryEdgeDetectors.canny(2, false, true, GrayF32.class, GrayF32.class);

		canny.process(input, threshLow, threshHigh, binary);

		// Only external contours are relevant
		List<Contour> contours = BinaryImageOps.contourExternal(binary, ConnectRule.EIGHT);

		Graphics2D g2 = displayImage.createGraphics();
		g2.setStroke(new BasicStroke(2));
		int minxCorner = image.getWidth();
		int maxxCorner = 0;
		int minyCorner = image.getHeight();
		int maxyCorner = 0;
		
		for (Contour c : contours) {
			for (Point2D_I32 pt : c.external) {
				minxCorner = Math.min(minxCorner, pt.getX());
				minyCorner = Math.min(minyCorner, pt.getY());

				maxxCorner = Math.max(maxxCorner, pt.getX());
				maxyCorner = Math.max(maxyCorner, pt.getY());
			}
		}
		int minXTheorical =  maxxCorner - expectedW;
		int maxXTheorical =  minxCorner + expectedW;
		if ((maxxCorner - minxCorner) > expectedW) {
			int cptMax = 0;
			int cptMin = 0;
			for (Contour c : contours) {
				for (Point2D_I32 pt : c.external) {
					if (pt.getX()> maxXTheorical) 
						cptMax++;
					if (pt.getX()< minXTheorical) 
						cptMin++;
				}
			}
			
			if (cptMin > cptMax) {
				maxxCorner = minxCorner + expectedW;
			} else {
				minxCorner = maxxCorner - expectedW;
			}
		} else if ((maxxCorner - minxCorner) < expectedW) {
			maxxCorner = minxCorner + expectedW;
		}
		
		int minYTheorical =  maxyCorner - expectedH;
		int maxYTheorical =  minyCorner + expectedH;
		if ((maxyCorner - minyCorner) > expectedH) {
			int cptMax = 0;
			int cptMin = 0;
			for (Contour c : contours) {
				for (Point2D_I32 pt : c.external) {
					if (pt.getY()> maxYTheorical) 
						cptMax++;
					if (pt.getY()< minYTheorical) 
						cptMin++;
				}
			}
			
			if (cptMin > cptMax) {
				maxyCorner = minyCorner + expectedH;
			} else {
				minyCorner = maxyCorner - expectedH;
			}
		} else if ((maxyCorner - minyCorner) < expectedH) {
			maxyCorner = minyCorner + expectedH;
		}
		
		 return image.getSubimage(minxCorner, minyCorner, Math.min(maxxCorner - minxCorner, image.getWidth() -minxCorner), Math.min(maxyCorner - minyCorner, image.getHeight() -minyCorner));
	}
	
	public static BufferedImage mirrorImage(BufferedImage img) throws IOException {
	      //Getting the height and with of the read image.
	      int height = img.getHeight();
	      int width = img.getWidth();
	      //Creating Buffered Image to store the output
	      BufferedImage res = new BufferedImage(width, height, BufferedImage.TYPE_INT_ARGB);
	      for(int j = 0; j < height; j++){
	         for(int i = 0, w = width - 1; i < width; i++, w--){
	            int p = img.getRGB(i, j);
	            //set mirror image pixel value - both left and right
	            res.setRGB(w, j, p);
	         }
	      }
	      return res;
	}
    
    public static IList<PhysicalBlock> classifyCode(final IScope scope, final List<BufferedImage> images, IList<PatternBlock> patterns, double thresholdMaxBlack, double thresholdMinWhite, int cols, int rows, double x0, double y0, double cx, double cy, float coeffContrast, boolean saveImage, boolean improveImage){
        int nbR = 0;
        int nbC = 0;
        Envelope3D envbounds = scope.getSimulation().getGeometry().getEnvelope() ;
		double coeffX = envbounds.getWidth() / cols;
		double coeffY=  envbounds.getHeight() /rows;
		thresholdMaxBlack *= coeffContrast;
		thresholdMinWhite *= coeffContrast;
		File outputfolder = new File(scope.getModel().getProjectPath() + "\\models\\generated\\subblocks");
		if (!outputfolder.exists()) {
			outputfolder.mkdir();
		}
		File outputfolder2 = new File(scope.getModel().getProjectPath() + "\\models\\generated\\blocks");
		if (!outputfolder2.exists()) {
			outputfolder2.mkdir();
		}
		
        IList<PhysicalBlock> blocks = GamaListFactory.create();
    	for(PatternBlock pb : patterns) {
    		nbR = Math.max(nbR, pb.getMatrix().numRows);
    		nbC = Math.max(nbC, pb.getMatrix().numCols);
        }
    	  try{
    		int x_g = 0;
    		int y_g = 0;
    		int cpt = 0;
    		int cpt2 = 0;
    		for ( BufferedImage img  : images) {
        		GamaIntMatrix l = new GamaIntMatrix(nbR, nbC);
        	     
        		int width = img.getWidth()/nbC;
	            int height = img.getHeight()/nbR;
	            for (int i = 0; i < nbC; i++){
	                for (int j = 0; j < nbR; j++){
	                    BufferedImage dest = img.getSubimage(Math.min(i*width, img.getWidth() - width), Math.min(j*height, img.getHeight() - height),width, height);
	                	// convert into a usable format
	                    Planar<GrayU8> color = ConvertBufferedImage.convertFrom(dest, true, ImageType.pl(3, GrayU8.class));

	            		// Declare storage space for converted gray scale images
	            		var weighted = new GrayU8(color.width, color.height);
	            		// display the results
	            		ColorRgb.rgbToGray_Weighted(color, weighted);
	            		ConvertBufferedImage.convertTo(weighted, dest);
	            		RescaleOp rescaleOp = new RescaleOp(coeffContrast, 0.0f, null);
	            		
	            		rescaleOp.filter(dest, dest);
	            		if (saveImage) {
	            			File outputfile = new File(scope.getModel().getProjectPath() + "\\models\\generated\\subblocks\\image_"+cpt+".jpg");
	                		ImageIO.write(dest, "jpg", outputfile);
		                    System.out.println("image_" + cpt + " -> " + getBlackIntensity(dest) + " i: "+i + " j: "+j + " black:  " + isBlack(dest,thresholdMaxBlack,thresholdMinWhite,improveImage) );
	            		}
	            		if(isBlack(dest,thresholdMaxBlack,thresholdMinWhite, improveImage)){
		                    l.set(scope, j, i, 0);
	                    }else {
	                        l.set(scope, j, i, 1);
	                    }
	                    cpt ++;
	                    
	                }
	            }
	            PhysicalBlock block = new PhysicalBlock();
	            blocks.add(block);
	            if (saveImage) {
	            	 File outputfile = new File(scope.getModel().getProjectPath() +"\\models\\generated\\blocks\\image_"+cpt2+".jpg" );
	                 ImageIO.write(img, "jpg", outputfile);
	                 System.out.println("image_" + cpt2 +  " -> l : " + l.serialize(false) + "  x_g: " + x_g+ "  y_g: " + x_g);
	            }
	            
                for (PatternBlock pb : patterns) {
	            	if (pb.getMatrix().equals(l)) {
	            		block.setPattern(pb);
	            		break;
	            	}
	            }
	            cpt2 ++;
	            block.setShape(new GamaPoint((x_g *  coeffX + coeffX/2) * cx + x0, (y_g * coeffY + coeffY/2) * cy + y0));
	            y_g ++; 
	            if (y_g >= rows) {
	            	y_g = 0;
	            	x_g ++;
	            }
        	}
        }catch (Exception e){
            e.printStackTrace();
        }

        return blocks;
    }
    
    
   @operator (
		   value = "save_webcam_image",
		   can_be_const = false
		   )
   @doc(
		   value = "saves the current webcam image in a file")
   public static boolean saveWebcamImage(final IScope scope, final GamaWebcam webcam, final String image_path, int width, int height) {
	   return webcam.saveImageAsFile(scope, image_path, width, height);
   }

    @operator (
			value = "crop_image",
			can_be_const = false,
			category = IOperatorCategory.LIST)
	@doc (
			value = "crop an image")
	public static String imageCropping(final IScope scope, final String pattern_path, final IShape geometry, final String  image_path, final IShape bounds)  {
    	File imageFile = new File(FileUtils.constructAbsoluteFilePath(scope, image_path, true));
		// check the required parameters 
		if (imageFile == null || imageFile.getName().trim().isEmpty())
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		BufferedImage tmpBfrImage = null;
		try {
			tmpBfrImage = ImageIO.read(imageFile);
		} catch (IOException tmpIoe) {
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		}
		if (tmpBfrImage == null)
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		Envelope3D envbounds = bounds == null ?scope.getSimulation().getGeometry().getEnvelope() : bounds.getEnvelope();
		double coeffX = tmpBfrImage.getWidth() / envbounds.getWidth();
		double coeffY= tmpBfrImage.getHeight()/ envbounds.getHeight();
		Envelope3D env = geometry.getEnvelope();
		BufferedImage dest = tmpBfrImage.getSubimage((int) Math.round((env.getMinX() - envbounds.getMinX()) * coeffX), (int) Math.round((env.getMinY()  - envbounds.getMinY())* coeffY), (int) Math.round(env.getWidth() * coeffX), (int) Math.round( env.getHeight() * coeffY));
		File outputfile = new File(FileUtils.constructAbsoluteFilePath(scope, pattern_path, false));
		try {

			String ext = Files.getFileExtension(outputfile.getAbsolutePath());
			
			ImageIO.write(dest, ext, outputfile);
		} catch (IOException e) {
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when writting file " + outputfile +": " + e, scope), true);
			
		}
		if (outputfile.exists())
			return outputfile.getAbsolutePath();
	    return null; 
		
    }
    
    private static Point2D_F64 toPoint2D(GamaPoint pt, double coeffX, double coeffY) {
    	 return new Point2D_F64(pt.x * coeffX,pt.y * coeffY);
    }
    
    @operator (
			value = "remove_perspective",
			can_be_const = false,
			category = IOperatorCategory.LIST)
	@doc (
			value = "remove the perspective from an image using 4 reference points (top-left, top-right, bottom-right, bottom-left)")
	public static String removePerspective(final IScope scope, final String outputPath, final String  image_path, IList<GamaPoint> map_corners)  {
    	BufferedImage flat = removeDistortion(scope, map_corners,getBufferedImage(scope, image_path));
		File outputfile = new File(FileUtils.constructAbsoluteFilePath(scope, outputPath, false));
		try {
			flat = mirrorImage(flat);
			String ext = Files.getFileExtension(outputfile.getAbsolutePath());
			ImageIO.write(flat, ext, outputfile);
		} catch (IOException e) {
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when writting file " + outputfile +": " + e, scope), true);
			
		}
		if (outputfile.exists())
			return outputfile.getAbsolutePath();
	    return null; 
       
    }
    
    public static BufferedImage getBufferedImage(final IScope scope, final String  image_path) {
    	File imageFile = new File(FileUtils.constructAbsoluteFilePath(scope, image_path, true));
		if (imageFile == null || imageFile.getName().trim().isEmpty())
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		BufferedImage tmpBfrImage = null;
		try {
			tmpBfrImage = ImageIO.read(imageFile);
		} catch (IOException tmpIoe) {
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		}
		if (tmpBfrImage == null)
			GAMA.reportError(scope, GamaRuntimeException.error("Problem when reading file " + image_path, scope), true);
		return tmpBfrImage;
    }
    
    public static BufferedImage removeDistortion(final IScope scope, final List<GamaPoint> points, BufferedImage tmpBfrImage) {
    	if (points.size() != 4) {
    		GAMA.reportError(scope, GamaRuntimeException.error("4 points have to be defined (top-left, top-right, bottom-right, bottom-left)", scope), true);
    	}
    	Envelope3D envbounds = scope.getSimulation().getGeometry().getEnvelope() ;
		double coeffX = tmpBfrImage.getWidth() / envbounds.getWidth();
		double coeffY= tmpBfrImage.getHeight()/ envbounds.getHeight();
		Planar<GrayF32> input = ConvertBufferedImage.convertFromPlanar(tmpBfrImage, null, true, GrayF32.class);
		Point2D_F64 PTL = toPoint2D(points.get(0), coeffX,coeffY);
		Point2D_F64 PTR = toPoint2D(points.get(1), coeffX,coeffY);
		Point2D_F64 PBR = toPoint2D(points.get(2), coeffX,coeffY);
		Point2D_F64 PBL = toPoint2D(points.get(3), coeffX,coeffY);
		
		int resWidth = (int) (coeffX * (points.get(1).x - points.get(0).x) ) ;
		int resHeight = (int) (coeffY * (points.get(2).y - points.get(0).y) ) ;
		
		
		RemovePerspectiveDistortion<Planar<GrayF32>> removePerspective =
				new RemovePerspectiveDistortion<>(resWidth, resHeight, ImageType.pl(3, GrayF32.class));

		// Specify the corners in the input image of the region.
		// Order matters! top-left, top-right, bottom-right, bottom-left
		if (!removePerspective.apply(input,
				PTL, PTR,PBR,PBL)) {
			GAMA.reportError(scope, GamaRuntimeException.error("Problem with distortion computation", scope), true);
		}

		Planar<GrayF32> output = removePerspective.getOutput();

		return ConvertBufferedImage.convertTo_F32(output, null, true);
    }

    public static double getBlackIntensity(final BufferedImage img){
    	
        int intensity = 0;
        int total = img.getHeight() * img.getWidth();
        for (int i = img.getMinX(); i < img.getWidth() ; i++) {
            for (int j = img.getMinTileY(); j < img.getHeight(); j++) {
                intensity  += img.getRGB(i,j) & 0xFF;
            }
        }
        return (0.0 + intensity) / (0.0 + total) ;
    }
    public static boolean isBlackNumberCanny(final BufferedImage img, float threshLow, float threshHigh){
    	GrayF32 input = ConvertBufferedImage.convertFromSingle(img, null, GrayF32.class);

		BufferedImage displayImage = new BufferedImage(input.width, input.height, BufferedImage.TYPE_INT_RGB);
		// Finds edges inside the image
		CannyEdge<GrayF32, GrayF32> canny = FactoryEdgeDetectors.canny(2, true, true, GrayF32.class, GrayF32.class);
		
		canny.process(input, 0.1f, 0.3f, null);
		List<EdgeContour> contours = canny.getContours();
		double sumPerimeters = 0;
		for (EdgeContour e : contours) {
			for (EdgeSegment s : e.segments) {
				double perimetersS = 0;
				List<PointIndex_I32> vertexes = ShapeFittingOps.fitPolygon(s.points, false, minSide, cornerPenalty);
				if (vertexes.isEmpty()) continue;
				PointIndex_I32 p0 = vertexes.get(0);
				for (int i = 1; i < vertexes.size() ; i++) {
					PointIndex_I32 p1 = vertexes.get(i);
					perimetersS += p1.distance(p0);
					p0 = p1;
				}
				sumPerimeters += perimetersS;
			}
		}
		System.out.println("Number: " + sumPerimeters);
		
		return sumPerimeters < 70.0;
		
    }
    
    public static BufferedImage improveImage(BufferedImage img) {
    	 Planar<GrayU8> color = ConvertBufferedImage.convertFrom(img, true, ImageType.PL_U8);
 		
         Planar<GrayU8> adjusted = color.createSameShape();

         GEnhanceImageOps.sharpen8(color, adjusted);
         img = ConvertBufferedImage.convertTo(adjusted, null, true);
 		
        color = ConvertBufferedImage.convertFrom(img, true, ImageType.PL_U8);
 		adjusted = color.createSameShape();

 		int[] histogram = new int[256];
 		int[] transform = new int[256];


 		// Apply the correction to each color band independently. Alternatively, you could compute the adjustment
 		// on a gray scale image then apply the same transform to each band
 		for (int bandIdx = 0; bandIdx < color.getNumBands(); bandIdx++) {
 			ImageStatistics.histogram(color.getBand(bandIdx), 0, histogram);
 			EnhanceImageOps.equalize(histogram, transform);
 			EnhanceImageOps.applyTransform(color.getBand(bandIdx), transform, adjusted.getBand(bandIdx));
 		}
 		
 		GEnhanceImageOps.equalizeLocal(color, 50, adjusted, 256, null);
 		img = ConvertBufferedImage.convertTo(adjusted, null, true);
 		return img;
    }
    public static boolean isBlack( BufferedImage img, double thresholdB, double thresholdW, boolean improveImage){
        int cptB = 0;
        int cptW = 0;

        if (improveImage)
        	img = improveImage(img);
		
         for (int i = img.getMinX(); i < img.getWidth() ; i++) {
            for (int j = img.getMinTileY(); j < img.getHeight(); j++) {
            	int intensity  = img.getRGB(i,j) & 0xFF;
               if (intensity <= thresholdB) 
            	   cptB++;
               if (intensity >= thresholdW) 
            	   cptW++;
            }
        }
        return cptB >=  cptW;
    }
	
    
    static private List<Double> computeThresholdBlackIntensity(final IScope scope, BufferedImage image, IShape blacksubBlock, IShape whitesubBlock, double tolerance, boolean saveImage, boolean improveImage ) {

    	Envelope3D env = scope.getSimulation().getGeometry().getEnvelope();
    	
    	Envelope3D envB = blacksubBlock.getEnvelope();
    	 if (improveImage)
    		 image = improveImage(image);
    	BufferedImage blackIm = image.getSubimage((int)(envB.getMinX() / env.getWidth() * image.getWidth()), (int)(envB.getMinY() / env.getHeight() * image.getHeight()), (int)(envB.getWidth() / env.getWidth() * image.getWidth()), (int)(envB.getHeight() / env.getHeight() * image.getHeight()));
    	double bI = getBlackIntensity(blackIm);
    	if (saveImage) {
    		File outputfile = new File(scope.getModel().getProjectPath() +"\\models\\generated\\image_black.jpg");
            try {
    			ImageIO.write(blackIm, "jpg", outputfile);
    		} catch (IOException e) {
    			e.printStackTrace();
    		}
    	}
    	
       
    	Envelope3D envW = whitesubBlock.getEnvelope();
    	BufferedImage whiteIm = image.getSubimage((int)(envW.getMinX() / env.getWidth() * image.getWidth()), (int)(envW.getMinY() / env.getHeight() * image.getHeight()), (int)(envW.getWidth() / env.getWidth() * image.getWidth()), (int)(envW.getHeight() / env.getHeight() * image.getHeight()));
    	double wI = getBlackIntensity(whiteIm);
    	
    	if (saveImage) {
    		File outputfile = new File(scope.getModel().getProjectPath() +"\\models\\generated\\image_white.jpg");
            try {
    			ImageIO.write(whiteIm, "jpg", outputfile);
    		} catch (IOException e) {
    			e.printStackTrace();
    		}
    	}
    	
    	wI = wI / tolerance;
        bI = bI * tolerance;
       
    	if (saveImage) 
    		System.out.println("Black Intensity: " + bI + " - White Intensity:" + wI);
    	
    	List<Double> res = new ArrayList<>();
    	res.add(bI);
    	res.add(wI);
    	return res;
    }
    
    
    @operator (
			value = "detect_blocks",
			can_be_const = false,
			category = "image")
	@doc (
			value = "detect the block from the image")
	public static IList<PhysicalBlock> detecBlocks(final IScope scope, String imagePath, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int resWidth, int resHeight, int cols, int rows, IShape blacksubBlock, IShape whitesubBlock, IShape bounds) {
    	return detecBlocks( scope, imagePath,  patterns, distorsionPoint, cols,  rows,  blacksubBlock,  whitesubBlock,  bounds, 1.0, 0.1f, 0.5f, 2.0f, false, false);

    }
    
    @operator (
			value = "detect_blocks",
			can_be_const = false,
			category = "image")
	@doc (
			value = "detect the block from the image")
	public static IList<PhysicalBlock> detecBlocks(final IScope scope, GamaWebcam webcam, final int webcamImageWidth, final int webcamImageHeight, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int cols, int rows, IShape blacksubBlock, IShape whitesubBlock, IShape bounds ) {
    	BufferedImage image = CamShotAct(scope,webcamImageWidth,webcamImageHeight, webcam);
    	return detecBlocks(scope, image,patterns, distorsionPoint, cols, rows, blacksubBlock, whitesubBlock, bounds, 1.0, 0.1f, 0.5f, 2.0f, false, false);
	}
    
    
    @operator (
			value = "detect_blocks",
			can_be_const = false,
			category = "image")
	@doc (
			value = "detect the block from the image")
	public static IList<PhysicalBlock> detecBlocks(final IScope scope, GamaWebcam webcam, final int webcamImageWidth, final int webcamImageHeight, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int cols, int rows, IShape blacksubBlock, IShape whitesubBlock, IShape bounds,double tolerance, double threshLow, double threshHigh, double coeffContrast, boolean saveImage, boolean improveImage ) {
    	BufferedImage image = CamShotAct(scope,webcamImageWidth,webcamImageHeight, webcam);
    	return detecBlocks(scope, image,patterns, distorsionPoint, cols, rows, blacksubBlock, whitesubBlock, bounds,tolerance, threshLow, threshHigh, coeffContrast,saveImage,  improveImage );
	}
    
    
   
    
    @operator (
			value = "detect_blocks",
			can_be_const = false,
			category = "image")
	@doc (
			value = "detect the block from the image")
	public static IList<PhysicalBlock> detecBlocks(final IScope scope, String imagePath, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int cols, int rows, IShape blacksubBlock, IShape whitesubBlock, IShape bounds,double tolerance, double threshLow, double threshHigh, double coeffContrast, boolean saveImage, boolean improveImage ) {
		
    	final BufferedImage image = getBufferedImage(scope, imagePath);
    	return detecBlocks(scope, image,patterns, distorsionPoint, cols, rows, blacksubBlock, whitesubBlock, bounds,tolerance, threshLow, threshHigh, coeffContrast,saveImage, improveImage );

	}
    

   
    
	public static IList<PhysicalBlock> detecBlocks(final IScope scope, BufferedImage image, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int cols, int rows, IShape blacksubBlock, IShape whitesubBlock, IShape bounds,double tolerance, double threshLow, double threshHigh, double coeffContrast, boolean saveImage, boolean improveImage ) {
		try {
			if (saveImage) {
				File outputfolder = new File(scope.getModel().getProjectPath() + "\\models\\generated");
				if (!outputfolder.exists()) {
					outputfolder.mkdir();
				}
			}
    		Envelope3D env = scope.getSimulation().getGeometry().getEnvelope();
        	int expectedW = (int)(bounds.getWidth() / env.getWidth() * image.getWidth()); 
    		int expectedH = (int)(bounds.getHeight() / env.getHeight() * image.getHeight());
    		List<Double> th =  computeThresholdBlackIntensity(scope, image, blacksubBlock, whitesubBlock, tolerance,saveImage, improveImage);
    		double thresholdMaxBlack = th.get(0);
    		double thresholdMinWhite = th.get(1);
    		return codeDetectBlocksFct(scope, image,patterns, distorsionPoint, cols, rows, thresholdMaxBlack , thresholdMinWhite, expectedW, expectedH, (float) threshLow, (float) threshHigh, (float) coeffContrast, saveImage, improveImage) ;
		} catch (IOException e) {
			e.printStackTrace();
		} 
    	return null;
	}
	
    private static IList<PhysicalBlock> codeDetectBlocksFct(final IScope scope, final BufferedImage image, final IList<PatternBlock> patterns, final IList<GamaPoint> distorsionPoint, int cols, int rows, double thresholdMaxBlack, double thresholdMinWhite, int expectedW, int expectedH, float threshLow, float threshHigh, float coeffContrast, boolean saveImage, boolean improveImage) throws IOException  {
    	BufferedImage imageWD = (distorsionPoint != null && (distorsionPoint.size() == 4)) ? removeDistortion(scope, distorsionPoint, image) : image; 
    	if (saveImage) {
    		File outputfile = new File(scope.getModel().getProjectPath() + "\\models\\generated\\image_distorsion.jpg");
    		ImageIO.write(imageWD, "jpg", outputfile);
    	}
    	
    	List<BufferedImage> imageGrid = cropGrid(imageWD, cols, rows, expectedW, expectedH, threshLow,  threshHigh );
    	Envelope3D envbounds = scope.getSimulation().getGeometry().getEnvelope() ;
 		
    	double x0 = Double.MAX_VALUE; double y0 = Double.MAX_VALUE; double xM = 0; double yM = 0;
    	if ((distorsionPoint != null && (distorsionPoint.size() == 4))) {
    		for (GamaPoint pt : distorsionPoint) {
    			x0 = Math.min(x0, pt.x);
    			xM = Math.max(xM, pt.x);
    			y0 = Math.min(y0, pt.y);
    			yM = Math.max(yM, pt.y);
    		}
    	} else {
    		xM = envbounds.getWidth();
    		yM = envbounds.getHeight();
    	}
    	
        return classifyCode(scope, imageGrid, patterns, thresholdMaxBlack, thresholdMinWhite, cols, rows, x0,y0, (xM -x0) / envbounds.getWidth(), (yM - y0)/ envbounds.getHeight(), coeffContrast, saveImage, improveImage);
    }
    
  
    

	@operator (
			value = "cam_shot",
			can_be_const = false,
			category = IOperatorCategory.LIST)
	@doc (
			value = "get a photoshot from the default webcam")
	public static IMatrix cam_shot(final IScope scope, final String filepath) {
		return cam_shot(scope, filepath, null, null,null);
	}
	
	@operator (
			value = "cam_shot",
			can_be_const = false,
			category = IOperatorCategory.LIST)
	@doc (
			value = "get a photoshot from the default webcam, with the given resolution (width, height) in pixels")
	public static IMatrix cam_shot(final IScope scope, final String filepath, final Integer width, final Integer height) {
		return cam_shot(scope, filepath, width, height, null);
	}
	
	@operator (
			value = "cam_shot",
			can_be_const = false,
			category = IOperatorCategory.LIST)
	@doc (
			value = "get a photoshot with the given resolution (width, height) in pixels from the given webcam")
	public static IMatrix cam_shot(final IScope scope, final String filepath, final Integer width, final Integer height, GamaWebcam webcam) {
		BufferedImage im = CamShotAct(scope, width, height, webcam);
		if (filepath != null && !filepath.isBlank()) {
			String path_gen = FileUtils.constructAbsoluteFilePath(scope, filepath, false);
			File outputfile = new File(path_gen);
	    	try {
				ImageIO.write(im, "jpg", outputfile);
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return  matrixValueFromImage(scope, im); 
	}
	
	private static BufferedImage CamShotAct(final IScope scope,final Integer width, final Integer height, GamaWebcam webcam) {
	
		if (webcam == null || webcam.getWebcam() == null) {
			GAMA.reportError(scope, GamaRuntimeException.error("No webcam detected", scope), false);
		}
		if (width != null && height != null)  {
			Dimension dim = new Dimension(width, height);
			if (!webcam.getWebcam().getViewSize().equals(dim)) {
				webcam.getWebcam().close();
				boolean nonStandard = true;
				for (int i = 0; i < webcam.getWebcam().getViewSizes().length; i++) {
					if (webcam.getWebcam().getViewSizes()[i].equals(dim)) {
						nonStandard = false;
						break;
					}
				}
				if (nonStandard) {
					Dimension[] nonStandardResolutions = new Dimension[] {dim};
					webcam.getWebcam().setCustomViewSizes(nonStandardResolutions);
				}
				webcam.getWebcam().setViewSize(dim);

				webcam.getWebcam().getLock().disable();
				webcam.getWebcam().open();
			}

		}
		BufferedImage bim = (BufferedImage) webcam.getWebcam().getImage(); 
		return bim;
	}
	
	private static IMatrix matrixValueFromImage(final IScope scope, final BufferedImage image) {
		int xSize, ySize;
		BufferedImage resultingImage = image;
		xSize = image.getWidth();
		ySize = image.getHeight();
		final IMatrix<Integer> matrix = new GamaIntMatrix(xSize, ySize);
		for (int i = 0; i < xSize; i++) {
			for (int j = 0; j < ySize; j++) {
				matrix.set(scope, i, j, resultingImage.getRGB(i, j));
			}
		}
		return matrix;
	}
	
}
